{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:51:30.967011Z",
     "iopub.status.busy": "2024-12-24T20:51:30.966658Z",
     "iopub.status.idle": "2024-12-24T20:51:42.720065Z",
     "shell.execute_reply": "2024-12-24T20:51:42.718726Z",
     "shell.execute_reply.started": "2024-12-24T20:51:30.966983Z"
    },
    "trusted": true
   },
   "source": [
    "! pip install onnx \n",
    "! pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:51:42.721980Z",
     "iopub.status.busy": "2024-12-24T20:51:42.721611Z",
     "iopub.status.idle": "2024-12-24T20:52:00.951273Z",
     "shell.execute_reply": "2024-12-24T20:52:00.950232Z",
     "shell.execute_reply.started": "2024-12-24T20:51:42.721938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "from torchvision.transforms import v2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models,transforms\n",
    "from transformers import pipeline\n",
    "import torchvision.transforms.functional as TF\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnxruntime.quantization import quantize_dynamic, quantize_static, QuantType, QuantFormat, create_calibrator, CalibrationMethod, CalibrationDataReader\n",
    "from transformers import AutoImageProcessor, AutoModelForDepthEstimation, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:00.953558Z",
     "iopub.status.busy": "2024-12-24T20:52:00.952952Z",
     "iopub.status.idle": "2024-12-24T20:52:00.959259Z",
     "shell.execute_reply": "2024-12-24T20:52:00.958212Z",
     "shell.execute_reply.started": "2024-12-24T20:52:00.953525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_to_onnx(model, sample_input, model_name):\n",
    "    \"\"\"Convert PyTorch model to ONNX format\"\"\"\n",
    "    model = model.cpu().eval()\n",
    "    with torch.no_grad():\n",
    "        torch.onnx.export(\n",
    "            model,                    # PyTorch model\n",
    "            sample_input,             # Sample input for tracing\n",
    "            f\"{model_name}.onnx\",     # Output file name\n",
    "            export_params=True,       # Store trained weights\n",
    "            opset_version=13,         # ONNX version\n",
    "            do_constant_folding=True, # Optimize constant foldings\n",
    "            input_names=['input'],    # Model input names\n",
    "            output_names=['output'],  # Model output names\n",
    "            dynamic_axes={            # Dynamic axes for variable batch size\n",
    "                'input': {0: 'batch_size'},\n",
    "                'output': {0: 'batch_size'}\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:00.961148Z",
     "iopub.status.busy": "2024-12-24T20:52:00.960833Z",
     "iopub.status.idle": "2024-12-24T20:52:00.983691Z",
     "shell.execute_reply": "2024-12-24T20:52:00.982585Z",
     "shell.execute_reply.started": "2024-12-24T20:52:00.961094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class QuntizationDataReader(CalibrationDataReader):\n",
    "    def __init__(self, loader,model,device):\n",
    "\n",
    "        self.torch_dl = loader\n",
    "        self.model=model\n",
    "        self.model.eval()\n",
    "        self.device=device\n",
    "        self.datasize = len(self.torch_dl)\n",
    "        self.enum_data = iter(self.torch_dl)\n",
    "\n",
    "    def to_numpy(self, pt_tensor):\n",
    "        return pt_tensor.detach().cpu().numpy() if pt_tensor.requires_grad else pt_tensor.cpu().numpy()\n",
    "\n",
    "    def get_next(self):\n",
    "        batch = next(self.enum_data, None)\n",
    "        if batch is not None:\n",
    "            inputs, binary_labels = batch\n",
    "            with torch.no_grad():\n",
    "                op = self.model(inputs.to(self.device))\n",
    "            return {'input': self.to_numpy(op)}\n",
    "        else:\n",
    "          return None\n",
    "\n",
    "    def rewind(self):\n",
    "        self.enum_data = iter(self.torch_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:00.985337Z",
     "iopub.status.busy": "2024-12-24T20:52:00.984803Z",
     "iopub.status.idle": "2024-12-24T20:52:01.009123Z",
     "shell.execute_reply": "2024-12-24T20:52:01.008135Z",
     "shell.execute_reply.started": "2024-12-24T20:52:00.985301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def quantize_onnx_model(model_path, quantized_model_name, calibration_data_loader,depth_map_model ,device,quantization_type='static'):\n",
    "    \"\"\"Quantize ONNX model using either dynamic or static quantization\"\"\"\n",
    "    if quantization_type == 'dynamic':\n",
    "        # Dynamic quantization\n",
    "        quantize_dynamic(\n",
    "            model_input=model_path,\n",
    "            model_output=f\"{quantized_model_name}.onnx\",\n",
    "            weight_type=QuantType.QUInt8,\n",
    "            per_channel=False,\n",
    "            reduce_range=False,\n",
    "            nodes_to_exclude=[]\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        # Static quantization with calibration\n",
    "        data_reader = QuntizationDataReader(calibration_data_loader,depth_map_model,device)\n",
    "\n",
    "        # Create calibrator with correct parameters\n",
    "\n",
    "        quantize_static(\n",
    "            model_input=model_path,\n",
    "            model_output=f\"{quantized_model_name}.onnx\",\n",
    "            calibration_data_reader=data_reader,\n",
    "            quant_format=QuantFormat.QDQ,\n",
    "            op_types_to_quantize=['Conv', 'MatMul', 'Gemm'],  # Specify operations to quantize\n",
    "            per_channel=False,\n",
    "            weight_type=QuantType.QInt8,  # Use Int8 quantization for weights\n",
    "            activation_type=QuantType.QInt8,  # Use Int8 quantization for activations\n",
    "            calibrate_method=CalibrationMethod.MinMax\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:01.010476Z",
     "iopub.status.busy": "2024-12-24T20:52:01.010201Z",
     "iopub.status.idle": "2024-12-24T20:52:01.037186Z",
     "shell.execute_reply": "2024-12-24T20:52:01.036117Z",
     "shell.execute_reply.started": "2024-12-24T20:52:01.010454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_inference_session(quantized_model_path):\n",
    "    \"\"\"Create ONNX Runtime inference session\"\"\"\n",
    "    # Set up ONNX Runtime options for Processor (Raspberry Pi)\n",
    "    options = onnxruntime.SessionOptions()\n",
    "    options.intra_op_num_threads = 4  # Adjust based on your Raspberry Pi's CPU\n",
    "    options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    \n",
    "    # Create inference session\n",
    "    session = onnxruntime.InferenceSession(\n",
    "        quantized_model_path,\n",
    "        options,\n",
    "        providers=['CPUExecutionProvider']\n",
    "    )\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:01.038553Z",
     "iopub.status.busy": "2024-12-24T20:52:01.038213Z",
     "iopub.status.idle": "2024-12-24T20:52:01.057703Z",
     "shell.execute_reply": "2024-12-24T20:52:01.056523Z",
     "shell.execute_reply.started": "2024-12-24T20:52:01.038507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset): \n",
    "    \n",
    "    def __init__(self, path, device, transform=None, img_size=(128, 128)):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.device = device\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.path = path\n",
    "        self.num_channels = 1\n",
    "        \n",
    "        for folder in os.listdir(self.path):\n",
    "            label = 1 if 'client' in folder else 0\n",
    "            for image in os.listdir(os.path.join(self.path, folder)):\n",
    "                if image.endswith('.jpg') or image.endswith('.png'):\n",
    "                    img_path = os.path.join(self.path, folder, image)\n",
    "                    self.images.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.images[idx]).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img= self.transform(img)\n",
    "            \n",
    "        return img, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:01.061669Z",
     "iopub.status.busy": "2024-12-24T20:52:01.061372Z",
     "iopub.status.idle": "2024-12-24T20:52:01.149340Z",
     "shell.execute_reply": "2024-12-24T20:52:01.148236Z",
     "shell.execute_reply.started": "2024-12-24T20:52:01.061646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img_size = (252, 252)\n",
    "batch_size = 10\n",
    "transf = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device('cpu')\n",
    "\n",
    "val_dataset = CustomDataset(\"/kaggle/input/increased-liveliness-detection/val\",device,transf,img_size=img_size)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:01.151827Z",
     "iopub.status.busy": "2024-12-24T20:52:01.151412Z",
     "iopub.status.idle": "2024-12-24T20:52:01.156711Z",
     "shell.execute_reply": "2024-12-24T20:52:01.155567Z",
     "shell.execute_reply.started": "2024-12-24T20:52:01.151795Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_inference(session, input_data):\n",
    "    \"\"\"Run inference using ONNX Runtime session\"\"\"\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "    \n",
    "    result = session.run([output_name], {input_name: input_data})\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:01.158036Z",
     "iopub.status.busy": "2024-12-24T20:52:01.157644Z",
     "iopub.status.idle": "2024-12-24T20:52:01.174191Z",
     "shell.execute_reply": "2024-12-24T20:52:01.173210Z",
     "shell.execute_reply.started": "2024-12-24T20:52:01.158009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FineTuneDepthAnything(nn.Module):\n",
    "    def __init__(self, device,load_trained=False,model_path=None):\n",
    "        super(FineTuneDepthAnything, self).__init__()\n",
    "        if load_trained:\n",
    "            config = AutoConfig.from_pretrained(\"depth-anything/Depth-Anything-V2-Small-hf\")\n",
    "            self.depth_anything = AutoModelForDepthEstimation.from_config(config)\n",
    "            state_dict = torch.load(model_path, map_location=device,weights_only=True)\n",
    "                \n",
    "            # Adjust keys in the state dictionary to match the model's keys\n",
    "            new_state_dict = {}\n",
    "            for key, value in state_dict.items():\n",
    "                new_key = key.replace(\"depth_anything.\", \"\")\n",
    "                new_state_dict[new_key] = value\n",
    "\n",
    "            # Load the adjusted state dictionary into the model\n",
    "            self.depth_anything.load_state_dict(new_state_dict)\n",
    "        else:\n",
    "            self.depth_anything = AutoModelForDepthEstimation.from_pretrained(\"depth-anything/Depth-Anything-V2-Small-hf\")\n",
    "            for name,param in self.depth_anything.named_parameters():\n",
    "                if 'head' in name or 'neck.fusion_stage.layers.2.residual_layer' in name or 'neck.fusion_stage.layers.3' in name:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        self.depth_anything = self.depth_anything.to(device)\n",
    "                \n",
    "    def forward(self, inp):\n",
    "        # print(f'inp shape: {inp.shape}')\n",
    "        return self.depth_anything(inp).predicted_depth.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:01.175627Z",
     "iopub.status.busy": "2024-12-24T20:52:01.175334Z",
     "iopub.status.idle": "2024-12-24T20:52:01.197095Z",
     "shell.execute_reply": "2024-12-24T20:52:01.195961Z",
     "shell.execute_reply.started": "2024-12-24T20:52:01.175603Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CDC(nn.Module):\n",
    "    '''\n",
    "    This class performs central difference convolution (CDC) operation. First the normal convolution is performed and then the difference convolution is performed. The output is the difference between the two is taken.\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,\n",
    "                 padding=1, dilation=1, groups=1, bias=False, theta=0.7):\n",
    "\n",
    "        super(CDC, self).__init__()\n",
    "        self.bias= bias\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.dilation = dilation\n",
    "        self.theta = theta\n",
    "        self.padding = padding\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_channels))\n",
    "        else:\n",
    "            self.bias = None\n",
    "            \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding if kernel_size==3 else 0, dilation=dilation, groups=groups, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_normal = self.conv(x)\n",
    "        # if conv.weight is (out_channels, in_channels, kernel_size, kernel_size),\n",
    "        # then the  self.conv.weight.sum(2) will return (out_channels, in_channels,kernel_size)\n",
    "        # and self.conv.weight.sum(2).sum(2) will return (out_channels,n_channels)\n",
    "        kernel_diff = self.conv.weight.sum(2).sum(2)\n",
    "        # Here we are adding extra dimensions such that the kernel_diff is of shape (out_channels, in_channels, 1, 1) so that convolution can be performed.\n",
    "        kernel_diff = kernel_diff[:, :, None, None]\n",
    "        out_diff = F.conv2d(input=x, weight=kernel_diff, bias=self.bias, stride=self.stride, padding=0, groups=self.groups)\n",
    "        return out_normal - self.theta * out_diff\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:01.198511Z",
     "iopub.status.busy": "2024-12-24T20:52:01.198211Z",
     "iopub.status.idle": "2024-12-24T20:52:01.218029Z",
     "shell.execute_reply": "2024-12-24T20:52:01.217065Z",
     "shell.execute_reply.started": "2024-12-24T20:52:01.198487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class conv_block_nested(nn.Module):\n",
    "    def __init__(self, in_ch,  out_ch):\n",
    "        super(conv_block_nested, self).__init__()\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.conv1 = CDC(in_ch, out_ch, kernel_size=3, padding=1, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = CDC(out_ch, out_ch, kernel_size=3, padding=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        output = self.activation(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:01.219540Z",
     "iopub.status.busy": "2024-12-24T20:52:01.219193Z",
     "iopub.status.idle": "2024-12-24T20:52:01.239123Z",
     "shell.execute_reply": "2024-12-24T20:52:01.238021Z",
     "shell.execute_reply.started": "2024-12-24T20:52:01.219501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ClassifierUCDCN(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(ClassifierUCDCN, self).__init__()\n",
    "        self.layers =8\n",
    "        self.dropout_prob = dropout\n",
    "        self.img_size = (252, 252)\n",
    "        self.hidden_size = 64\n",
    "        self.conv1 = conv_block_nested(1,self.layers)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = conv_block_nested(self.layers,1)\n",
    "        # Maxpool\n",
    "        self.linear_1 = nn.Linear((self.img_size[0]//4 * self.img_size[1]//4), self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "        self.linear_2 = nn.Linear(self.hidden_size, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        conv1 = self.conv1(inp)\n",
    "        maxpool = self.maxpool(conv1)\n",
    "        conv2 = self.conv2(maxpool)\n",
    "        maxpool2 = self.maxpool(conv2)\n",
    "        linear_1 = self.linear_1(maxpool2.view(-1, self.img_size[0]//4 * self.img_size[1]//4))\n",
    "        relu = self.relu(linear_1)\n",
    "        dropout = self.dropout(relu)\n",
    "        linear_2 = self.linear_2(dropout)\n",
    "        return self.sigmoid(linear_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:01.240575Z",
     "iopub.status.busy": "2024-12-24T20:52:01.240196Z",
     "iopub.status.idle": "2024-12-24T20:52:06.531359Z",
     "shell.execute_reply": "2024-12-24T20:52:06.530215Z",
     "shell.execute_reply.started": "2024-12-24T20:52:01.240538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "depth_map_model = FineTuneDepthAnything(device, load_trained=True, model_path='/kaggle/input/finetune_depth_anything/pytorch/63_epochs_trained/1/fine_tuning_depth_anything.pth').to(device)\n",
    "sample_input = torch.randn((1,3,img_size[0],img_size[1]))\n",
    "convert_to_onnx(depth_map_model,sample_input,'depth_map_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:06.533589Z",
     "iopub.status.busy": "2024-12-24T20:52:06.533173Z",
     "iopub.status.idle": "2024-12-24T20:52:06.728228Z",
     "shell.execute_reply": "2024-12-24T20:52:06.727292Z",
     "shell.execute_reply.started": "2024-12-24T20:52:06.533534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classifier = ClassifierUCDCN(dropout=0.5).to(device)\n",
    "classifier.load_state_dict(torch.load('/kaggle/input/finetune_depth_anyhting_classifier/pytorch/64_size_7_epochs_trained/1/64_finetune_depth_anything_classifier.pth',map_location=device,weights_only=True))\n",
    "sample_input_classifier = torch.randn((1,1,img_size[0],img_size[1]))\n",
    "convert_to_onnx(classifier,sample_input_classifier,'classifier_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:06.729551Z",
     "iopub.status.busy": "2024-12-24T20:52:06.729268Z",
     "iopub.status.idle": "2024-12-24T20:52:08.594055Z",
     "shell.execute_reply": "2024-12-24T20:52:08.593033Z",
     "shell.execute_reply.started": "2024-12-24T20:52:06.729527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "quantize_onnx_model('/kaggle/working/depth_map_model.onnx',\"depth_quantized_model\",None, depth_map_model,device,\"dynamic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T19:47:06.845345Z",
     "iopub.status.busy": "2024-12-24T19:47:06.844879Z",
     "iopub.status.idle": "2024-12-24T20:32:19.147377Z",
     "shell.execute_reply": "2024-12-24T20:32:19.145426Z",
     "shell.execute_reply.started": "2024-12-24T19:47:06.845315Z"
    }
   },
   "outputs": [],
   "source": [
    "quantize_onnx_model('/kaggle/working/classifier_model.onnx',\"classifier_quantized_model\", val_loader,depth_map_model, device,\"static\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:08.603255Z",
     "iopub.status.busy": "2024-12-24T20:52:08.602836Z",
     "iopub.status.idle": "2024-12-24T20:52:08.934970Z",
     "shell.execute_reply": "2024-12-24T20:52:08.933927Z",
     "shell.execute_reply.started": "2024-12-24T20:52:08.603216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('/kaggle/working/depth_map_model.onnx')\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:08.936693Z",
     "iopub.status.busy": "2024-12-24T20:52:08.936285Z",
     "iopub.status.idle": "2024-12-24T20:52:08.948853Z",
     "shell.execute_reply": "2024-12-24T20:52:08.947879Z",
     "shell.execute_reply.started": "2024-12-24T20:52:08.936656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('/kaggle/working/classifier_model.onnx')\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:08.950382Z",
     "iopub.status.busy": "2024-12-24T20:52:08.950006Z",
     "iopub.status.idle": "2024-12-24T20:52:09.020863Z",
     "shell.execute_reply": "2024-12-24T20:52:09.019720Z",
     "shell.execute_reply.started": "2024-12-24T20:52:08.950349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('/kaggle/working/depth_quantized_model.onnx')\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:32:19.626301Z",
     "iopub.status.busy": "2024-12-24T20:32:19.625926Z",
     "iopub.status.idle": "2024-12-24T20:32:19.643568Z",
     "shell.execute_reply": "2024-12-24T20:32:19.642252Z",
     "shell.execute_reply.started": "2024-12-24T20:32:19.626270Z"
    }
   },
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('/kaggle/working/classifier_quantized_model.onnx')\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:09.022596Z",
     "iopub.status.busy": "2024-12-24T20:52:09.022180Z",
     "iopub.status.idle": "2024-12-24T20:52:09.476863Z",
     "shell.execute_reply": "2024-12-24T20:52:09.475149Z",
     "shell.execute_reply.started": "2024-12-24T20:52:09.022556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "depth_session = create_inference_session('/kaggle/working/depth_map_model.onnx')\n",
    "classifier_session = create_inference_session('/kaggle/working/classifier_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T20:52:09.477938Z",
     "iopub.status.busy": "2024-12-24T20:52:09.477640Z",
     "iopub.status.idle": "2024-12-24T20:52:09.869983Z",
     "shell.execute_reply": "2024-12-24T20:52:09.868843Z",
     "shell.execute_reply.started": "2024-12-24T20:52:09.477913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "depth_session = create_inference_session('/kaggle/working/depth_quantized_model.onnx')\n",
    "classifier_session = create_inference_session('/kaggle/working/classifier_quantized_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6345867,
     "sourceId": 10258327,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 103067,
     "modelInstanceId": 176431,
     "sourceId": 206950,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 106709,
     "modelInstanceId": 177671,
     "sourceId": 208397,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
