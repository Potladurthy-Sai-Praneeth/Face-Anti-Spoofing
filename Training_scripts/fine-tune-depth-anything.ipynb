{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:38:57.487015Z",
     "iopub.status.busy": "2024-12-20T22:38:57.4867Z",
     "iopub.status.idle": "2024-12-20T22:39:18.532798Z",
     "shell.execute_reply": "2024-12-20T22:39:18.531935Z",
     "shell.execute_reply.started": "2024-12-20T22:38:57.486992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "import torchvision.transforms.functional as TF\n",
    "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:18.534405Z",
     "iopub.status.busy": "2024-12-20T22:39:18.533912Z",
     "iopub.status.idle": "2024-12-20T22:39:18.541771Z",
     "shell.execute_reply": "2024-12-20T22:39:18.540717Z",
     "shell.execute_reply.started": "2024-12-20T22:39:18.534378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset): \n",
    "    \n",
    "    def __init__(self, path, device, transform=None, img_size=(128, 128)):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.device = device\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.path = path\n",
    "        self.num_channels = 1\n",
    "        \n",
    "        for folder in os.listdir(self.path):\n",
    "            label = 1 if 'client' in folder else 0\n",
    "            for image in os.listdir(os.path.join(self.path, folder)):\n",
    "                if image.endswith('.jpg') or image.endswith('.png'):\n",
    "                    img_path = os.path.join(self.path, folder, image)\n",
    "                    self.images.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.images[idx]).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img= self.transform(img)\n",
    "            \n",
    "        return img, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:18.544157Z",
     "iopub.status.busy": "2024-12-20T22:39:18.543895Z",
     "iopub.status.idle": "2024-12-20T22:39:18.563446Z",
     "shell.execute_reply": "2024-12-20T22:39:18.562738Z",
     "shell.execute_reply.started": "2024-12-20T22:39:18.544133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SimulateDistanceTransform:\n",
    "    def __init__(self, min_scale=0.5, max_scale=1.0):\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Randomly choose a scale factor\n",
    "        scale_factor = random.uniform(self.min_scale, self.max_scale)\n",
    "        \n",
    "        # Get original dimensions\n",
    "        original_width, original_height = img.size\n",
    "        \n",
    "        # Calculate new dimensions\n",
    "        new_width = int(original_width * scale_factor)\n",
    "        new_height = int(original_height * scale_factor)\n",
    "        \n",
    "        # Resize the image\n",
    "        img = transforms.Resize((new_height, new_width))(img)\n",
    "        \n",
    "        # Pad the image to the original size\n",
    "        padding = (\n",
    "            (original_width - new_width) // 2,\n",
    "            (original_height - new_height) // 2,\n",
    "            (original_width - new_width + 1) // 2,\n",
    "            (original_height - new_height + 1) // 2\n",
    "        )\n",
    "        img = transforms.Pad(padding,padding_mode='edge')(img)\n",
    "        \n",
    "        # Optional: Apply a slight blur\n",
    "        if scale_factor < 0.65:\n",
    "            img = transforms.GaussianBlur(kernel_size=3)(img)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:18.625209Z",
     "iopub.status.busy": "2024-12-20T22:39:18.625001Z",
     "iopub.status.idle": "2024-12-20T22:39:19.476553Z",
     "shell.execute_reply": "2024-12-20T22:39:19.475872Z",
     "shell.execute_reply.started": "2024-12-20T22:39:18.62519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img_size = (252, 252)\n",
    "batch_size = 80\n",
    "\n",
    "transf = transforms.Compose([\n",
    "    SimulateDistanceTransform(min_scale=0.4, max_scale=1.0),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = CustomDataset(\"/kaggle/input/increased-liveliness-detection/train\",device,transf,img_size=img_size)\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(\"/kaggle/input/increased-liveliness-detection/val\",device,transf,img_size=img_size)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "# test_dataset = CustomDataset(\"/kaggle/input/increased-liveliness-detection/test\",device,transf,img_size=img_size)\n",
    "# test_loader = prepare_dataloader(test_dataset,batch_size=batch_size//world_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:19.479382Z",
     "iopub.status.busy": "2024-12-20T22:39:19.479156Z",
     "iopub.status.idle": "2024-12-20T22:39:19.487734Z",
     "shell.execute_reply": "2024-12-20T22:39:19.486602Z",
     "shell.execute_reply.started": "2024-12-20T22:39:19.479362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CDC(nn.Module):\n",
    "    '''\n",
    "    This class performs central difference convolution (CDC) operation. First the normal convolution is performed and then the difference convolution is performed. The output is the difference between the two is taken.\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,\n",
    "                 padding=1, dilation=1, groups=1, bias=False, theta=0.7):\n",
    "\n",
    "        super(CDC, self).__init__()\n",
    "        self.bias= bias\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.dilation = dilation\n",
    "        self.theta = theta\n",
    "        self.padding = padding\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_channels))\n",
    "        else:\n",
    "            self.bias = None\n",
    "            \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding if kernel_size==3 else 0, dilation=dilation, groups=groups, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_normal = self.conv(x)\n",
    "        # if conv.weight is (out_channels, in_channels, kernel_size, kernel_size),\n",
    "        # then the  self.conv.weight.sum(2) will return (out_channels, in_channels,kernel_size)\n",
    "        # and self.conv.weight.sum(2).sum(2) will return (out_channels,n_channels)\n",
    "        kernel_diff = self.conv.weight.sum(2).sum(2)\n",
    "        # Here we are adding extra dimensions such that the kernel_diff is of shape (out_channels, in_channels, 1, 1) so that convolution can be performed.\n",
    "        kernel_diff = kernel_diff[:, :, None, None]\n",
    "        out_diff = F.conv2d(input=x, weight=kernel_diff, bias=self.bias, stride=self.stride, padding=0, groups=self.groups)\n",
    "        return out_normal - self.theta * out_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:19.489988Z",
     "iopub.status.busy": "2024-12-20T22:39:19.489587Z",
     "iopub.status.idle": "2024-12-20T22:39:19.52255Z",
     "shell.execute_reply": "2024-12-20T22:39:19.521564Z",
     "shell.execute_reply.started": "2024-12-20T22:39:19.489947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FineTuneDepthAnything(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(FineTuneDepthAnything, self).__init__()\n",
    "        self.depth_anything = AutoModelForDepthEstimation.from_pretrained(\"depth-anything/Depth-Anything-V2-Small-hf\")\n",
    "        for name,param in self.depth_anything.named_parameters():\n",
    "            if 'head' in name or 'neck.fusion_stage.layers.2.residual_layer' in name or 'neck.fusion_stage.layers.3' in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.depth_anything = self.depth_anything.to(device)\n",
    "                \n",
    "    def forward(self, inp):\n",
    "        return self.depth_anything(inp).predicted_depth.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:19.523815Z",
     "iopub.status.busy": "2024-12-20T22:39:19.523515Z",
     "iopub.status.idle": "2024-12-20T22:39:19.546628Z",
     "shell.execute_reply": "2024-12-20T22:39:19.545983Z",
     "shell.execute_reply.started": "2024-12-20T22:39:19.523792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def contrast_depth_conv(input_tensor, device):\n",
    "    \"\"\"\n",
    "    Compute contrast depth using depthwise convolution.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_tensor: A tensor of shape (N, C, H, W), expected to be (N, 1, 32, 32)\n",
    "    - device: The device (CPU/GPU) the tensors should be processed on\n",
    "    \n",
    "    Returns:\n",
    "    - A tensor of shape (N, 8, H, W) representing the contrast depth\n",
    "    \"\"\"\n",
    "    # Ensure the input tensor is of the correct shape by removing any extra channel dimension\n",
    "    input_tensor = input_tensor.squeeze(1)\n",
    "\n",
    "    # Define the 8 different 3x3 kernel filters for contrast depth computation\n",
    "    kernel_filter_list = [\n",
    "        [[1, 0, 0], [0, -1, 0], [0, 0, 0]], [[0, 1, 0], [0, -1, 0], [0, 0, 0]], [[0, 0, 1], [0, -1, 0], [0, 0, 0]],\n",
    "        [[0, 0, 0], [1, -1, 0], [0, 0, 0]], [[0, 0, 0], [0, -1, 1], [0, 0, 0]],\n",
    "        [[0, 0, 0], [0, -1, 0], [1, 0, 0]], [[0, 0, 0], [0, -1, 0], [0, 1, 0]], [[0, 0, 0], [0, -1, 0], [0, 0, 1]]\n",
    "    ]\n",
    "    \n",
    "    # Convert the list of kernel filters into a PyTorch tensor and send it to the specified device\n",
    "    kernel_filter = torch.tensor(kernel_filter_list, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Add an extra dimension to the kernel filters to match the expected shape for conv2d (out_channels, in_channels, H, W)\n",
    "    kernel_filter = kernel_filter.unsqueeze(dim=1)\n",
    "    \n",
    "    # Expand the input tensor to have 8 channels to match the number of kernel filters\n",
    "    input_expanded = input_tensor.unsqueeze(dim=1).expand(-1, 8, -1, -1)\n",
    "    \n",
    "    # Perform depthwise convolution using the defined kernel filters\n",
    "    contrast_depth = F.conv2d(input_expanded, weight=kernel_filter, groups=8)\n",
    "    \n",
    "    return contrast_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:19.547665Z",
     "iopub.status.busy": "2024-12-20T22:39:19.547459Z",
     "iopub.status.idle": "2024-12-20T22:39:19.5664Z",
     "shell.execute_reply": "2024-12-20T22:39:19.565774Z",
     "shell.execute_reply.started": "2024-12-20T22:39:19.547638Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def customLoss(criterion,mse_criterion,predictions,labels,device):\n",
    "\n",
    "    smooth_loss = criterion(predictions, labels)\n",
    "    contrast_pred = contrast_depth_conv(predictions,device)\n",
    "    contrast_label = contrast_depth_conv(labels,device)\n",
    "    contrast_loss = mse_criterion(contrast_pred, contrast_label)\n",
    "\n",
    "    return 0.3*smooth_loss + contrast_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:19.567293Z",
     "iopub.status.busy": "2024-12-20T22:39:19.567105Z",
     "iopub.status.idle": "2024-12-20T22:39:24.176375Z",
     "shell.execute_reply": "2024-12-20T22:39:24.175456Z",
     "shell.execute_reply.started": "2024-12-20T22:39:19.567276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = FineTuneDepthAnything(device).to(device)\n",
    "model.load_state_dict(torch.load('/kaggle/input/finetune_depth_anything/pytorch/54_epochs_trained/1/fine_tuning_depth_anything.pth',map_location=device,weights_only=False))\n",
    "model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:24.177729Z",
     "iopub.status.busy": "2024-12-20T22:39:24.177321Z",
     "iopub.status.idle": "2024-12-20T22:39:56.993783Z",
     "shell.execute_reply": "2024-12-20T22:39:56.992872Z",
     "shell.execute_reply.started": "2024-12-20T22:39:24.177666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "large_depth_map_model = AutoModelForDepthEstimation.from_pretrained(\"depth-anything/Depth-Anything-V2-Large-hf\").to(device) # LiheYoung/depth-anything-base-hf\n",
    "large_depth_map_model = torch.nn.DataParallel(large_depth_map_model, device_ids=[0,1]).to(device)\n",
    "large_depth_map_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:56.994972Z",
     "iopub.status.busy": "2024-12-20T22:39:56.994624Z",
     "iopub.status.idle": "2024-12-20T22:39:57.000112Z",
     "shell.execute_reply": "2024-12-20T22:39:56.999414Z",
     "shell.execute_reply.started": "2024-12-20T22:39:56.994944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.SmoothL1Loss()\n",
    "mse_criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "num_epochs = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:57.000936Z",
     "iopub.status.busy": "2024-12-20T22:39:57.000737Z",
     "iopub.status.idle": "2024-12-20T22:39:59.982892Z",
     "shell.execute_reply": "2024-12-20T22:39:59.982118Z",
     "shell.execute_reply.started": "2024-12-20T22:39:57.000918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_depth_maps(outputs, labels, binary):\n",
    "    # Initialize the index dictionary with None values\n",
    "    index = {0: None, 1: None}\n",
    "    \n",
    "    # Try to find the first occurrence of 0 and 1, if they exist\n",
    "    for label in [0, 1]:\n",
    "        matches = (binary == label).nonzero(as_tuple=True)[0]\n",
    "        if len(matches) > 0:\n",
    "            index[label] = matches[0].item()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 4, figsize=(12, 5))\n",
    "    \n",
    "    # Plot for label 0 if it exists\n",
    "    if index[0] is not None:\n",
    "        ax[0].imshow(outputs[index[0]].cpu().detach().squeeze(0).squeeze(0).numpy())\n",
    "        ax[0].set_title('Predictions for label 0')\n",
    "        ax[1].imshow(labels[index[0]].cpu().detach().squeeze(0).numpy())\n",
    "        ax[1].set_title('Ground truth for label 0')\n",
    "    else:\n",
    "        ax[0].set_visible(False)\n",
    "        ax[1].set_visible(False)\n",
    "    \n",
    "    # Plot for label 1 if it exists\n",
    "    if index[1] is not None:\n",
    "        ax[2].imshow(outputs[index[1]].cpu().detach().squeeze(0).squeeze(0).numpy())\n",
    "        ax[2].set_title('Predictions for label 1')\n",
    "        ax[3].imshow(labels[index[1]].cpu().detach().squeeze(0).numpy())\n",
    "        ax[3].set_title('Ground truth for label 1')\n",
    "    else:\n",
    "        ax[2].set_visible(False)\n",
    "        ax[3].set_visible(False)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T22:39:59.984154Z",
     "iopub.status.busy": "2024-12-20T22:39:59.983841Z",
     "iopub.status.idle": "2024-12-20T22:40:00.003013Z",
     "shell.execute_reply": "2024-12-20T22:40:00.002382Z",
     "shell.execute_reply.started": "2024-12-20T22:39:59.984125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_labels(inputs, label):\n",
    "    mask = label.view(-1, 1, 1, 1) == 1\n",
    "    return torch.where(mask, inputs, torch.zeros_like(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-20T23:19:11.415Z",
     "iopub.execute_input": "2024-12-20T22:40:00.004094Z",
     "iopub.status.busy": "2024-12-20T22:40:00.003819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "best_epoch_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, binary_labels = data\n",
    "        inputs, binary_labels = inputs.to(device), binary_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = large_depth_map_model(inputs)\n",
    "            depth_maps = out.predicted_depth.unsqueeze(1)\n",
    "\n",
    "        labels = get_labels(depth_maps, binary_labels)\n",
    "        loss = customLoss(criterion, mse_criterion, outputs, labels, device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss.append(running_loss)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {running_loss} and lr is {optimizer.param_groups[0]['lr']}\")\n",
    "    plot_depth_maps(outputs,labels,binary_labels)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()  \n",
    "        with torch.no_grad():\n",
    "            running_loss_test = 0.0\n",
    "            for i, data in enumerate(val_loader, 0):\n",
    "                inputs_test,  binary_labels_test = data\n",
    "                inputs_test, binary_labels_test = inputs_test.to(device), binary_labels_test.to(device)\n",
    "                outputs_test= model(inputs_test)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    out = large_depth_map_model(inputs_test)\n",
    "                    depth_maps_test = out.predicted_depth.unsqueeze(1)\n",
    "\n",
    "                labels_test = get_labels(depth_maps_test, binary_labels_test)\n",
    "                loss_test = customLoss(criterion,mse_criterion, outputs_test, labels_test,device)\n",
    "\n",
    "                running_loss_test += loss_test.item()\n",
    "                \n",
    "            val_loss.append(running_loss_test)\n",
    "            print(f\"Validation Loss: {running_loss_test}\")\n",
    "            plot_depth_maps(outputs_test,labels_test,binary_labels_test)\n",
    "            \n",
    "            if running_loss_test < best_epoch_loss:\n",
    "                best_epoch_loss = running_loss_test\n",
    "                torch.save(model.module.state_dict(), \"best_fine_tuning_depth_anything.pth\")\n",
    "                \n",
    "    torch.save(model.module.state_dict(), \"fine_tuning_depth_anything.pth\")\n",
    "    scheduler.step(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "best_epoch_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    # train_loader.sampler.set_epoch(epoch)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, binary_labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        binary_labels = binary_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = large_depth_map_model(inputs)\n",
    "            depth_maps = out.predicted_depth.unsqueeze(1)\n",
    "        \n",
    "        labels = get_labels(depth_maps, binary_labels)\n",
    "        loss = customLoss(criterion, mse_criterion, outputs, labels, device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Synchronize loss across all processes\n",
    "    dist.all_reduce(torch.tensor(running_loss).to(device))\n",
    "    running_loss /= world_size\n",
    "    \n",
    "    if local_rank == 0:\n",
    "        train_loss.append(running_loss)\n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {running_loss} and lr is {optimizer.param_groups[0]['lr']}\")\n",
    "        \n",
    "    # Validation every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            running_loss_test = 0.0\n",
    "            \n",
    "            for i, data in enumerate(val_loader):\n",
    "                inputs_test, binary_labels_test = data\n",
    "                inputs_test = inputs_test.to(device)\n",
    "                binary_labels_test = binary_labels_test.to(device)\n",
    "                \n",
    "                outputs_test = model(inputs_test)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    out = large_depth_map_model(inputs_test)\n",
    "                    depth_maps_test = out.predicted_depth.unsqueeze(1)\n",
    "                \n",
    "                labels_test = get_labels(depth_maps_test, binary_labels_test)\n",
    "                loss_test = customLoss(criterion, mse_criterion, outputs_test, labels_test, device)\n",
    "                running_loss_test += loss_test.item()\n",
    "            \n",
    "            # Synchronize validation loss\n",
    "            dist.all_reduce(torch.tensor(running_loss_test).to(device))\n",
    "            running_loss_test /= world_size\n",
    "            \n",
    "            if local_rank == 0:\n",
    "                val_loss.append(running_loss_test)\n",
    "                print(f\"Validation Loss: {running_loss_test}\")\n",
    "                \n",
    "                if running_loss_test < best_epoch_loss:\n",
    "                    best_epoch_loss = running_loss_test\n",
    "                    torch.save(model.module.state_dict(), \"best_fine_tuning_depth_anything.pth\")\n",
    "    \n",
    "    if local_rank == 0:\n",
    "        torch.save(model.module.state_dict(), \"fine_tuning_depth_anything.pth\")\n",
    "    \n",
    "    scheduler.step(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6341400,
     "sourceId": 10252081,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 102590,
     "modelInstanceId": 175634,
     "sourceId": 205923,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
